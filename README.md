# ObjectDetection-CoreML-Vision
In this project Im using CoreML and Vision to detect object from photo gallery or live capture using iPhone camera. In first case we can choose photo from our photo gallery using ImagePicker(To integrate UIKit and SwiftUI im using UIViewRepresentable) then CoreML proccesing it to detect object and confidence. In second case the Vision framework, can recognize objects in live capture. Vision requests made with a Core ML model return results as VNRecognizedObjectObservation objects, which identify objects found in the captured scene with coordiantions.

<h3>Few screenshots</h3>
  <img src="1.GIF" alt="drawing" width="200"/>
  <img src="1.png" alt="drawing" width="200"/>
  <img src="2.png" alt="drawing" width="200"/>
  <img src="3.png" alt="drawing" width="200"/>
 
